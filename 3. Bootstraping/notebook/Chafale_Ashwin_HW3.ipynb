{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Name : Ashwin Chafale\n",
    "### Github unsername : chafale\n",
    "### USC-ID : 1990624801"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1 (a) Loading the [AReM data](https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+\\%28AReM\\%29)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = r\"../data/AReM\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Loading bending1 data\n",
    "bending1_ds1 = pd.read_csv(os.path.join(path, \"bending1\", \"dataset1.csv\"), skiprows=4)\n",
    "bending1_ds2 = pd.read_csv(os.path.join(path, \"bending1\", \"dataset2.csv\"), skiprows=4)\n",
    "bending1_ds3 = pd.read_csv(os.path.join(path, \"bending1\", \"dataset3.csv\"), skiprows=4)\n",
    "bending1_ds4 = pd.read_csv(os.path.join(path, \"bending1\", \"dataset4.csv\"), skiprows=4)\n",
    "bending1_ds5 = pd.read_csv(os.path.join(path, \"bending1\", \"dataset5.csv\"), skiprows=4)\n",
    "bending1_ds6 = pd.read_csv(os.path.join(path, \"bending1\", \"dataset6.csv\"), skiprows=4)\n",
    "bending1_ds7 = pd.read_csv(os.path.join(path, \"bending1\", \"dataset7.csv\"), skiprows=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Loading bending2 data\n",
    "bending2_ds1 = pd.read_csv(os.path.join(path, \"bending2\", \"dataset1.csv\"), skiprows=4)\n",
    "bending2_ds2 = pd.read_csv(os.path.join(path, \"bending2\", \"dataset2.csv\"), skiprows=4)\n",
    "bending2_ds3 = pd.read_csv(os.path.join(path, \"bending2\", \"dataset3.csv\"), skiprows=4)\n",
    "bending2_ds4 = pd.read_csv(os.path.join(path, \"bending2\", \"dataset4.csv\"), skiprows=4)\n",
    "bending2_ds5 = pd.read_csv(os.path.join(path, \"bending2\", \"dataset5.csv\"), skiprows=4)\n",
    "bending2_ds6 = pd.read_csv(os.path.join(path, \"bending2\", \"dataset6.csv\"), skiprows=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Loading cycling data\n",
    "cycling_ds1 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset1.csv\"), skiprows=4)\n",
    "cycling_ds2 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset2.csv\"), skiprows=4)\n",
    "cycling_ds3 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset3.csv\"), skiprows=4)\n",
    "cycling_ds4 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset4.csv\"), skiprows=4)\n",
    "cycling_ds5 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset5.csv\"), skiprows=4)\n",
    "cycling_ds6 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset6.csv\"), skiprows=4)\n",
    "cycling_ds7 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset7.csv\"), skiprows=4)\n",
    "cycling_ds8 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset8.csv\"), skiprows=4)\n",
    "cycling_ds9 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset9.csv\"), skiprows=4) # removed extra comma from eof\n",
    "cycling_ds10 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset10.csv\"), skiprows=4)\n",
    "cycling_ds11 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset11.csv\"), skiprows=4)\n",
    "cycling_ds12 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset12.csv\"), skiprows=4)\n",
    "cycling_ds13 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset13.csv\"), skiprows=4)\n",
    "cycling_ds14 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset14.csv\"), skiprows=4) # removed extra comma from eof\n",
    "cycling_ds15 = pd.read_csv(os.path.join(path, \"cycling\", \"dataset15.csv\"), skiprows=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Loading lying data\n",
    "lying_ds1 = pd.read_csv(os.path.join(path, \"lying\", \"dataset1.csv\"), skiprows=4)\n",
    "lying_ds2 = pd.read_csv(os.path.join(path, \"lying\", \"dataset2.csv\"), skiprows=4)\n",
    "lying_ds3 = pd.read_csv(os.path.join(path, \"lying\", \"dataset3.csv\"), skiprows=4)\n",
    "lying_ds4 = pd.read_csv(os.path.join(path, \"lying\", \"dataset4.csv\"), skiprows=4)\n",
    "lying_ds5 = pd.read_csv(os.path.join(path, \"lying\", \"dataset5.csv\"), skiprows=4)\n",
    "lying_ds6 = pd.read_csv(os.path.join(path, \"lying\", \"dataset6.csv\"), skiprows=4)\n",
    "lying_ds7 = pd.read_csv(os.path.join(path, \"lying\", \"dataset7.csv\"), skiprows=4)\n",
    "lying_ds8 = pd.read_csv(os.path.join(path, \"lying\", \"dataset8.csv\"), skiprows=4)\n",
    "lying_ds9 = pd.read_csv(os.path.join(path, \"lying\", \"dataset9.csv\"), skiprows=4)\n",
    "lying_ds10 = pd.read_csv(os.path.join(path, \"lying\", \"dataset10.csv\"), skiprows=4)\n",
    "lying_ds11 = pd.read_csv(os.path.join(path, \"lying\", \"dataset11.csv\"), skiprows=4)\n",
    "lying_ds12 = pd.read_csv(os.path.join(path, \"lying\", \"dataset12.csv\"), skiprows=4)\n",
    "lying_ds13 = pd.read_csv(os.path.join(path, \"lying\", \"dataset13.csv\"), skiprows=4)\n",
    "lying_ds14 = pd.read_csv(os.path.join(path, \"lying\", \"dataset14.csv\"), skiprows=4)\n",
    "lying_ds15 = pd.read_csv(os.path.join(path, \"lying\", \"dataset15.csv\"), skiprows=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Loading sitting data\n",
    "sitting_ds1 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset1.csv\"), skiprows=4)\n",
    "sitting_ds2 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset2.csv\"), skiprows=4)\n",
    "sitting_ds3 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset3.csv\"), skiprows=4)\n",
    "sitting_ds4 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset4.csv\"), skiprows=4)\n",
    "sitting_ds5 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset5.csv\"), skiprows=4)\n",
    "sitting_ds6 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset6.csv\"), skiprows=4)\n",
    "sitting_ds7 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset7.csv\"), skiprows=4)\n",
    "sitting_ds8 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset8.csv\"), skiprows=4)\n",
    "sitting_ds9 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset9.csv\"), skiprows=4)\n",
    "sitting_ds10 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset10.csv\"), skiprows=4)\n",
    "sitting_ds11 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset11.csv\"), skiprows=4)\n",
    "sitting_ds12 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset12.csv\"), skiprows=4)\n",
    "sitting_ds13 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset13.csv\"), skiprows=4)\n",
    "sitting_ds14 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset14.csv\"), skiprows=4)\n",
    "sitting_ds15 = pd.read_csv(os.path.join(path, \"sitting\", \"dataset15.csv\"), skiprows=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Loading standing data\n",
    "standing_ds1 = pd.read_csv(os.path.join(path, \"standing\", \"dataset1.csv\"), skiprows=4)\n",
    "standing_ds2 = pd.read_csv(os.path.join(path, \"standing\", \"dataset2.csv\"), skiprows=4)\n",
    "standing_ds3 = pd.read_csv(os.path.join(path, \"standing\", \"dataset3.csv\"), skiprows=4)\n",
    "standing_ds4 = pd.read_csv(os.path.join(path, \"standing\", \"dataset4.csv\"), skiprows=4)\n",
    "standing_ds5 = pd.read_csv(os.path.join(path, \"standing\", \"dataset5.csv\"), skiprows=4)\n",
    "standing_ds6 = pd.read_csv(os.path.join(path, \"standing\", \"dataset6.csv\"), skiprows=4)\n",
    "standing_ds7 = pd.read_csv(os.path.join(path, \"standing\", \"dataset7.csv\"), skiprows=4)\n",
    "standing_ds8 = pd.read_csv(os.path.join(path, \"standing\", \"dataset8.csv\"), skiprows=4)\n",
    "standing_ds9 = pd.read_csv(os.path.join(path, \"standing\", \"dataset9.csv\"), skiprows=4)\n",
    "standing_ds10 = pd.read_csv(os.path.join(path, \"standing\", \"dataset10.csv\"), skiprows=4)\n",
    "standing_ds11 = pd.read_csv(os.path.join(path, \"standing\", \"dataset11.csv\"), skiprows=4)\n",
    "standing_ds12 = pd.read_csv(os.path.join(path, \"standing\", \"dataset12.csv\"), skiprows=4)\n",
    "standing_ds13 = pd.read_csv(os.path.join(path, \"standing\", \"dataset13.csv\"), skiprows=4)\n",
    "standing_ds14 = pd.read_csv(os.path.join(path, \"standing\", \"dataset14.csv\"), skiprows=4)\n",
    "standing_ds15 = pd.read_csv(os.path.join(path, \"standing\", \"dataset15.csv\"), skiprows=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Loading walking data\n",
    "walking_ds1 = pd.read_csv(os.path.join(path, \"walking\", \"dataset1.csv\"), skiprows=4)\n",
    "walking_ds2 = pd.read_csv(os.path.join(path, \"walking\", \"dataset2.csv\"), skiprows=4)\n",
    "walking_ds3 = pd.read_csv(os.path.join(path, \"walking\", \"dataset3.csv\"), skiprows=4)\n",
    "walking_ds4 = pd.read_csv(os.path.join(path, \"walking\", \"dataset4.csv\"), skiprows=4)\n",
    "walking_ds5 = pd.read_csv(os.path.join(path, \"walking\", \"dataset5.csv\"), skiprows=4)\n",
    "walking_ds6 = pd.read_csv(os.path.join(path, \"walking\", \"dataset6.csv\"), skiprows=4)\n",
    "walking_ds7 = pd.read_csv(os.path.join(path, \"walking\", \"dataset7.csv\"), skiprows=4)\n",
    "walking_ds8 = pd.read_csv(os.path.join(path, \"walking\", \"dataset8.csv\"), skiprows=4)\n",
    "walking_ds9 = pd.read_csv(os.path.join(path, \"walking\", \"dataset9.csv\"), skiprows=4)\n",
    "walking_ds10 = pd.read_csv(os.path.join(path, \"walking\", \"dataset10.csv\"), skiprows=4)\n",
    "walking_ds11 = pd.read_csv(os.path.join(path, \"walking\", \"dataset11.csv\"), skiprows=4)\n",
    "walking_ds12 = pd.read_csv(os.path.join(path, \"walking\", \"dataset12.csv\"), skiprows=4)\n",
    "walking_ds13 = pd.read_csv(os.path.join(path, \"walking\", \"dataset13.csv\"), skiprows=4)\n",
    "walking_ds14 = pd.read_csv(os.path.join(path, \"walking\", \"dataset14.csv\"), skiprows=4)\n",
    "walking_ds15 = pd.read_csv(os.path.join(path, \"walking\", \"dataset15.csv\"), skiprows=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "bending1 = [0, bending1_ds1, bending1_ds2, bending1_ds3, bending1_ds4, bending1_ds5, bending1_ds6, bending1_ds7]\n",
    "\n",
    "bending2 = [0, bending2_ds1, bending2_ds2, bending2_ds3, bending2_ds4, bending2_ds5, bending2_ds6]\n",
    "\n",
    "cycling = [0, cycling_ds1, cycling_ds2, cycling_ds3, cycling_ds4, cycling_ds5, cycling_ds6, cycling_ds7, cycling_ds8, cycling_ds9, cycling_ds10, cycling_ds11, cycling_ds12, cycling_ds13, cycling_ds14, cycling_ds15]\n",
    "\n",
    "lying = [0, lying_ds1, lying_ds2, lying_ds3, lying_ds4, lying_ds5, lying_ds6, lying_ds7, lying_ds8, lying_ds9, lying_ds10, lying_ds11, lying_ds12, lying_ds13, lying_ds14, lying_ds15]\n",
    "\n",
    "sitting = [0, sitting_ds1, sitting_ds2, sitting_ds3, sitting_ds4, sitting_ds5, sitting_ds6, sitting_ds7, sitting_ds8, sitting_ds9, sitting_ds10, sitting_ds11, sitting_ds12, sitting_ds13, sitting_ds14, sitting_ds15]\n",
    "\n",
    "standing = [0, standing_ds1, standing_ds2, standing_ds3, standing_ds4, standing_ds5, standing_ds6, standing_ds7, standing_ds8, standing_ds9, standing_ds10, standing_ds11, standing_ds12, standing_ds13, standing_ds14, standing_ds15]\n",
    "\n",
    "walking = [0, walking_ds1, walking_ds2, walking_ds3, walking_ds4, walking_ds5, walking_ds6, walking_ds7, walking_ds8, walking_ds9, walking_ds10, walking_ds11, walking_ds12, walking_ds13, walking_ds14, walking_ds15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1 (b) Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1, 2, and 3 in other folders as test data and other datasets as train data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "testList = [bending1_ds1, bending1_ds2, bending2_ds1, bending2_ds2, cycling_ds1, cycling_ds2, cycling_ds3, lying_ds1, lying_ds2, lying_ds3, sitting_ds1, sitting_ds2, sitting_ds3, standing_ds1, standing_ds2, standing_ds3, walking_ds1, walking_ds2, walking_ds3]\n",
    "\n",
    "trainingList = [bending1_ds3, bending1_ds4, bending1_ds5, bending1_ds6, bending1_ds7, bending2_ds3, bending2_ds4, bending2_ds5, bending2_ds6, cycling_ds4, cycling_ds5, cycling_ds6, cycling_ds7, cycling_ds8, cycling_ds9, cycling_ds10, cycling_ds11, cycling_ds12, cycling_ds13, cycling_ds14, cycling_ds15, lying_ds4, lying_ds5, lying_ds6, lying_ds7, lying_ds8, lying_ds9, lying_ds10, lying_ds11, lying_ds12, lying_ds13, lying_ds14, lying_ds15, sitting_ds4, sitting_ds5, sitting_ds6, sitting_ds7, sitting_ds8, sitting_ds9, sitting_ds10, sitting_ds11, sitting_ds12, sitting_ds13, sitting_ds14, sitting_ds15, standing_ds4, standing_ds5, standing_ds6, standing_ds7, standing_ds8, standing_ds9, standing_ds10, standing_ds11, standing_ds12, standing_ds13, standing_ds14, standing_ds15, walking_ds4, walking_ds5, walking_ds6, walking_ds7, walking_ds8, walking_ds9, walking_ds10, walking_ds11, walking_ds12, walking_ds13, walking_ds14, walking_ds15]\n",
    "\n",
    "testData = pd.concat(testList)\n",
    "trainingData = pd.concat(trainingList)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1 (c) Feature Extraction\n",
    "\n",
    "### 1 (c) i. Research what types of time-domain features are usually used in time series classification and list them (examples are minimum, maximum, mean, etc)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer\n",
    "- #### `Means` in each of the *d* dimensions\n",
    "- #### `Standard deviations` of the *d* dimensions\n",
    "- #### `Skewness`, `Kurtosis` and `Higher order moments` of the *d* dimensions\n",
    "- #### `Maximum`, `Minimum` and `Median` values\n",
    "- #### `first quartile` and `third quartile`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1 (c) ii. Extract the time-domain features minimum, maximum, mean, median, standard deviation, first quartile, and third quartile for all of the 6 time series in each instance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Extracting minimum\n",
    "bending1_min1 = []\n",
    "bending1_min2 = []\n",
    "bending1_min3 = []\n",
    "bending1_min4 = []\n",
    "bending1_min5 = []\n",
    "bending1_min6 = []\n",
    "for i in range(1,8):\n",
    "    bending1_min1.append(np.min(bending1[i].avg_rss12))\n",
    "    bending1_min2.append(np.min(bending1[i].var_rss12))\n",
    "    bending1_min3.append(np.min(bending1[i].avg_rss13))\n",
    "    bending1_min4.append(np.min(bending1[i].var_rss13))\n",
    "    bending1_min5.append(np.min(bending1[i].avg_rss23))\n",
    "    bending1_min6.append(np.min(bending1[i].var_rss23))\n",
    "\n",
    "\n",
    "bending2_min1 = []\n",
    "bending2_min2 = []\n",
    "bending2_min3 = []\n",
    "bending2_min4 = []\n",
    "bending2_min5 = []\n",
    "bending2_min6 = []\n",
    "for i in range(1,7):\n",
    "    bending2_min1.append(np.min(bending2[i].avg_rss12))\n",
    "    bending2_min2.append(np.min(bending2[i].var_rss12))\n",
    "    bending2_min3.append(np.min(bending2[i].avg_rss13))\n",
    "    bending2_min4.append(np.min(bending2[i].var_rss13))\n",
    "    bending2_min5.append(np.min(bending2[i].avg_rss23))\n",
    "    bending2_min6.append(np.min(bending2[i].var_rss23))\n",
    "\n",
    "\n",
    "cycling_min1 = []\n",
    "cycling_min2 = []\n",
    "cycling_min3 = []\n",
    "cycling_min4 = []\n",
    "cycling_min5 = []\n",
    "cycling_min6 = []\n",
    "for i in range(1,16):\n",
    "    cycling_min1.append(np.min(cycling[i].avg_rss12))\n",
    "    cycling_min2.append(np.min(cycling[i].var_rss12))\n",
    "    cycling_min3.append(np.min(cycling[i].avg_rss13))\n",
    "    cycling_min4.append(np.min(cycling[i].var_rss13))\n",
    "    cycling_min5.append(np.min(cycling[i].avg_rss23))\n",
    "    cycling_min6.append(np.min(cycling[i].var_rss23))\n",
    "\n",
    "\n",
    "lying_min1 = []\n",
    "lying_min2 = []\n",
    "lying_min3 = []\n",
    "lying_min4 = []\n",
    "lying_min5 = []\n",
    "lying_min6 = []\n",
    "for i in range(1,16):\n",
    "    lying_min1.append(np.min(lying[i].avg_rss12))\n",
    "    lying_min2.append(np.min(lying[i].var_rss12))\n",
    "    lying_min3.append(np.min(lying[i].avg_rss13))\n",
    "    lying_min4.append(np.min(lying[i].var_rss13))\n",
    "    lying_min5.append(np.min(lying[i].avg_rss23))\n",
    "    lying_min6.append(np.min(lying[i].var_rss23))\n",
    "\n",
    "\n",
    "sitting_min1 = []\n",
    "sitting_min2 = []\n",
    "sitting_min3 = []\n",
    "sitting_min4 = []\n",
    "sitting_min5 = []\n",
    "sitting_min6 = []\n",
    "for i in range(1,16):\n",
    "    sitting_min1.append(np.min(sitting[i].avg_rss12))\n",
    "    sitting_min2.append(np.min(sitting[i].var_rss12))\n",
    "    sitting_min3.append(np.min(sitting[i].avg_rss13))\n",
    "    sitting_min4.append(np.min(sitting[i].var_rss13))\n",
    "    sitting_min5.append(np.min(sitting[i].avg_rss23))\n",
    "    sitting_min6.append(np.min(sitting[i].var_rss23))\n",
    "\n",
    "\n",
    "standing_min1 = []\n",
    "standing_min2 = []\n",
    "standing_min3 = []\n",
    "standing_min4 = []\n",
    "standing_min5 = []\n",
    "standing_min6 = []\n",
    "for i in range(1,16):\n",
    "    standing_min1.append(np.min(standing[i].avg_rss12))\n",
    "    standing_min2.append(np.min(standing[i].var_rss12))\n",
    "    standing_min3.append(np.min(standing[i].avg_rss13))\n",
    "    standing_min4.append(np.min(standing[i].var_rss13))\n",
    "    standing_min5.append(np.min(standing[i].avg_rss23))\n",
    "    standing_min6.append(np.min(standing[i].var_rss23))\n",
    "\n",
    "\n",
    "walking_min1 = []\n",
    "walking_min2 = []\n",
    "walking_min3 = []\n",
    "walking_min4 = []\n",
    "walking_min5 = []\n",
    "walking_min6 = []\n",
    "for i in range(1,16):\n",
    "    walking_min1.append(np.min(walking[i].avg_rss12))\n",
    "    walking_min2.append(np.min(walking[i].var_rss12))\n",
    "    walking_min3.append(np.min(walking[i].avg_rss13))\n",
    "    walking_min4.append(np.min(walking[i].var_rss13))\n",
    "    walking_min5.append(np.min(walking[i].avg_rss23))\n",
    "    walking_min6.append(np.min(walking[i].var_rss23))\n",
    "\n",
    "\n",
    "min1 = bending1_min1 + bending2_min1 + cycling_min1 + lying_min1 + sitting_min1 + standing_min1 + walking_min1\n",
    "min2 = bending1_min2 + bending2_min2 + cycling_min2 + lying_min2 + sitting_min2 + standing_min2 + walking_min2\n",
    "min3 = bending1_min3 + bending2_min3 + cycling_min3 + lying_min3 + sitting_min3 + standing_min3 + walking_min3\n",
    "min4 = bending1_min4 + bending2_min4 + cycling_min4 + lying_min4 + sitting_min4 + standing_min4 + walking_min4\n",
    "min5 = bending1_min5 + bending2_min5 + cycling_min5 + lying_min5 + sitting_min5 + standing_min5 + walking_min5\n",
    "min6 = bending1_min6 + bending2_min6 + cycling_min6 + lying_min6 + sitting_min6 + standing_min6 + walking_min6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Extracting maximum\n",
    "bending1_max1 = []\n",
    "bending1_max2 = []\n",
    "bending1_max3 = []\n",
    "bending1_max4 = []\n",
    "bending1_max5 = []\n",
    "bending1_max6 = []\n",
    "for i in range(1,8):\n",
    "    bending1_max1.append(np.max(bending1[i].avg_rss12))\n",
    "    bending1_max2.append(np.max(bending1[i].var_rss12))\n",
    "    bending1_max3.append(np.max(bending1[i].avg_rss13))\n",
    "    bending1_max4.append(np.max(bending1[i].var_rss13))\n",
    "    bending1_max5.append(np.max(bending1[i].avg_rss23))\n",
    "    bending1_max6.append(np.max(bending1[i].var_rss23))\n",
    "\n",
    "\n",
    "bending2_max1 = []\n",
    "bending2_max2 = []\n",
    "bending2_max3 = []\n",
    "bending2_max4 = []\n",
    "bending2_max5 = []\n",
    "bending2_max6 = []\n",
    "for i in range(1,7):\n",
    "    bending2_max1.append(np.max(bending2[i].avg_rss12))\n",
    "    bending2_max2.append(np.max(bending2[i].var_rss12))\n",
    "    bending2_max3.append(np.max(bending2[i].avg_rss13))\n",
    "    bending2_max4.append(np.max(bending2[i].var_rss13))\n",
    "    bending2_max5.append(np.max(bending2[i].avg_rss23))\n",
    "    bending2_max6.append(np.max(bending2[i].var_rss23))\n",
    "\n",
    "\n",
    "cycling_max1 = []\n",
    "cycling_max2 = []\n",
    "cycling_max3 = []\n",
    "cycling_max4 = []\n",
    "cycling_max5 = []\n",
    "cycling_max6 = []\n",
    "for i in range(1,16):\n",
    "    cycling_max1.append(np.max(cycling[i].avg_rss12))\n",
    "    cycling_max2.append(np.max(cycling[i].var_rss12))\n",
    "    cycling_max3.append(np.max(cycling[i].avg_rss13))\n",
    "    cycling_max4.append(np.max(cycling[i].var_rss13))\n",
    "    cycling_max5.append(np.max(cycling[i].avg_rss23))\n",
    "    cycling_max6.append(np.max(cycling[i].var_rss23))\n",
    "\n",
    "\n",
    "lying_max1 = []\n",
    "lying_max2 = []\n",
    "lying_max3 = []\n",
    "lying_max4 = []\n",
    "lying_max5 = []\n",
    "lying_max6 = []\n",
    "for i in range(1,16):\n",
    "    lying_max1.append(np.max(lying[i].avg_rss12))\n",
    "    lying_max2.append(np.max(lying[i].var_rss12))\n",
    "    lying_max3.append(np.max(lying[i].avg_rss13))\n",
    "    lying_max4.append(np.max(lying[i].var_rss13))\n",
    "    lying_max5.append(np.max(lying[i].avg_rss23))\n",
    "    lying_max6.append(np.max(lying[i].var_rss23))\n",
    "\n",
    "\n",
    "sitting_max1 = []\n",
    "sitting_max2 = []\n",
    "sitting_max3 = []\n",
    "sitting_max4 = []\n",
    "sitting_max5 = []\n",
    "sitting_max6 = []\n",
    "for i in range(1,16):\n",
    "    sitting_max1.append(np.max(sitting[i].avg_rss12))\n",
    "    sitting_max2.append(np.max(sitting[i].var_rss12))\n",
    "    sitting_max3.append(np.max(sitting[i].avg_rss13))\n",
    "    sitting_max4.append(np.max(sitting[i].var_rss13))\n",
    "    sitting_max5.append(np.max(sitting[i].avg_rss23))\n",
    "    sitting_max6.append(np.max(sitting[i].var_rss23))\n",
    "\n",
    "\n",
    "standing_max1 = []\n",
    "standing_max2 = []\n",
    "standing_max3 = []\n",
    "standing_max4 = []\n",
    "standing_max5 = []\n",
    "standing_max6 = []\n",
    "for i in range(1,16):\n",
    "    standing_max1.append(np.max(standing[i].avg_rss12))\n",
    "    standing_max2.append(np.max(standing[i].var_rss12))\n",
    "    standing_max3.append(np.max(standing[i].avg_rss13))\n",
    "    standing_max4.append(np.max(standing[i].var_rss13))\n",
    "    standing_max5.append(np.max(standing[i].avg_rss23))\n",
    "    standing_max6.append(np.max(standing[i].var_rss23))\n",
    "\n",
    "\n",
    "walking_max1 = []\n",
    "walking_max2 = []\n",
    "walking_max3 = []\n",
    "walking_max4 = []\n",
    "walking_max5 = []\n",
    "walking_max6 = []\n",
    "for i in range(1,16):\n",
    "    walking_max1.append(np.max(walking[i].avg_rss12))\n",
    "    walking_max2.append(np.max(walking[i].var_rss12))\n",
    "    walking_max3.append(np.max(walking[i].avg_rss13))\n",
    "    walking_max4.append(np.max(walking[i].var_rss13))\n",
    "    walking_max5.append(np.max(walking[i].avg_rss23))\n",
    "    walking_max6.append(np.max(walking[i].var_rss23))\n",
    "\n",
    "\n",
    "max1 = bending1_max1 + bending2_max1 + cycling_max1 + lying_max1 + sitting_max1 + standing_max1 + walking_max1\n",
    "max2 = bending1_max2 + bending2_max2 + cycling_max2 + lying_max2 + sitting_max2 + standing_max2 + walking_max2\n",
    "max3 = bending1_max3 + bending2_max3 + cycling_max3 + lying_max3 + sitting_max3 + standing_max3 + walking_max3\n",
    "max4 = bending1_max4 + bending2_max4 + cycling_max4 + lying_max4 + sitting_max4 + standing_max4 + walking_max4\n",
    "max5 = bending1_max5 + bending2_max5 + cycling_max5 + lying_max5 + sitting_max5 + standing_max5 + walking_max5\n",
    "max6 = bending1_max6 + bending2_max6 + cycling_max6 + lying_max6 + sitting_max6 + standing_max6 + walking_max6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Extracting mean\n",
    "bending1_mean1 = []\n",
    "bending1_mean2 = []\n",
    "bending1_mean3 = []\n",
    "bending1_mean4 = []\n",
    "bending1_mean5 = []\n",
    "bending1_mean6 = []\n",
    "for i in range(1,8):\n",
    "    bending1_mean1.append(np.mean(bending1[i].avg_rss12))\n",
    "    bending1_mean2.append(np.mean(bending1[i].var_rss12))\n",
    "    bending1_mean3.append(np.mean(bending1[i].avg_rss13))\n",
    "    bending1_mean4.append(np.mean(bending1[i].var_rss13))\n",
    "    bending1_mean5.append(np.mean(bending1[i].avg_rss23))\n",
    "    bending1_mean6.append(np.mean(bending1[i].var_rss23))\n",
    "\n",
    "\n",
    "bending2_mean1 = []\n",
    "bending2_mean2 = []\n",
    "bending2_mean3 = []\n",
    "bending2_mean4 = []\n",
    "bending2_mean5 = []\n",
    "bending2_mean6 = []\n",
    "for i in range(1,7):\n",
    "    bending2_mean1.append(np.mean(bending2[i].avg_rss12))\n",
    "    bending2_mean2.append(np.mean(bending2[i].var_rss12))\n",
    "    bending2_mean3.append(np.mean(bending2[i].avg_rss13))\n",
    "    bending2_mean4.append(np.mean(bending2[i].var_rss13))\n",
    "    bending2_mean5.append(np.mean(bending2[i].avg_rss23))\n",
    "    bending2_mean6.append(np.mean(bending2[i].var_rss23))\n",
    "\n",
    "\n",
    "cycling_mean1 = []\n",
    "cycling_mean2 = []\n",
    "cycling_mean3 = []\n",
    "cycling_mean4 = []\n",
    "cycling_mean5 = []\n",
    "cycling_mean6 = []\n",
    "for i in range(1,16):\n",
    "    cycling_mean1.append(np.mean(cycling[i].avg_rss12))\n",
    "    cycling_mean2.append(np.mean(cycling[i].var_rss12))\n",
    "    cycling_mean3.append(np.mean(cycling[i].avg_rss13))\n",
    "    cycling_mean4.append(np.mean(cycling[i].var_rss13))\n",
    "    cycling_mean5.append(np.mean(cycling[i].avg_rss23))\n",
    "    cycling_mean6.append(np.mean(cycling[i].var_rss23))\n",
    "\n",
    "\n",
    "lying_mean1 = []\n",
    "lying_mean2 = []\n",
    "lying_mean3 = []\n",
    "lying_mean4 = []\n",
    "lying_mean5 = []\n",
    "lying_mean6 = []\n",
    "for i in range(1,16):\n",
    "    lying_mean1.append(np.mean(lying[i].avg_rss12))\n",
    "    lying_mean2.append(np.mean(lying[i].var_rss12))\n",
    "    lying_mean3.append(np.mean(lying[i].avg_rss13))\n",
    "    lying_mean4.append(np.mean(lying[i].var_rss13))\n",
    "    lying_mean5.append(np.mean(lying[i].avg_rss23))\n",
    "    lying_mean6.append(np.mean(lying[i].var_rss23))\n",
    "\n",
    "\n",
    "sitting_mean1 = []\n",
    "sitting_mean2 = []\n",
    "sitting_mean3 = []\n",
    "sitting_mean4 = []\n",
    "sitting_mean5 = []\n",
    "sitting_mean6 = []\n",
    "for i in range(1,16):\n",
    "    sitting_mean1.append(np.mean(sitting[i].avg_rss12))\n",
    "    sitting_mean2.append(np.mean(sitting[i].var_rss12))\n",
    "    sitting_mean3.append(np.mean(sitting[i].avg_rss13))\n",
    "    sitting_mean4.append(np.mean(sitting[i].var_rss13))\n",
    "    sitting_mean5.append(np.mean(sitting[i].avg_rss23))\n",
    "    sitting_mean6.append(np.mean(sitting[i].var_rss23))\n",
    "\n",
    "\n",
    "standing_mean1 = []\n",
    "standing_mean2 = []\n",
    "standing_mean3 = []\n",
    "standing_mean4 = []\n",
    "standing_mean5 = []\n",
    "standing_mean6 = []\n",
    "for i in range(1,16):\n",
    "    standing_mean1.append(np.mean(standing[i].avg_rss12))\n",
    "    standing_mean2.append(np.mean(standing[i].var_rss12))\n",
    "    standing_mean3.append(np.mean(standing[i].avg_rss13))\n",
    "    standing_mean4.append(np.mean(standing[i].var_rss13))\n",
    "    standing_mean5.append(np.mean(standing[i].avg_rss23))\n",
    "    standing_mean6.append(np.mean(standing[i].var_rss23))\n",
    "\n",
    "\n",
    "walking_mean1 = []\n",
    "walking_mean2 = []\n",
    "walking_mean3 = []\n",
    "walking_mean4 = []\n",
    "walking_mean5 = []\n",
    "walking_mean6 = []\n",
    "for i in range(1,16):\n",
    "    walking_mean1.append(np.mean(walking[i].avg_rss12))\n",
    "    walking_mean2.append(np.mean(walking[i].var_rss12))\n",
    "    walking_mean3.append(np.mean(walking[i].avg_rss13))\n",
    "    walking_mean4.append(np.mean(walking[i].var_rss13))\n",
    "    walking_mean5.append(np.mean(walking[i].avg_rss23))\n",
    "    walking_mean6.append(np.mean(walking[i].var_rss23))\n",
    "\n",
    "\n",
    "mean1 = bending1_mean1 + bending2_mean1 + cycling_mean1 + lying_mean1 + sitting_mean1 + standing_mean1 + walking_mean1\n",
    "mean2 = bending1_mean2 + bending2_mean2 + cycling_mean2 + lying_mean2 + sitting_mean2 + standing_mean2 + walking_mean2\n",
    "mean3 = bending1_mean3 + bending2_mean3 + cycling_mean3 + lying_mean3 + sitting_mean3 + standing_mean3 + walking_mean3\n",
    "mean4 = bending1_mean4 + bending2_mean4 + cycling_mean4 + lying_mean4 + sitting_mean4 + standing_mean4 + walking_mean4\n",
    "mean5 = bending1_mean5 + bending2_mean5 + cycling_mean5 + lying_mean5 + sitting_mean5 + standing_mean5 + walking_mean5\n",
    "mean6 = bending1_mean6 + bending2_mean6 + cycling_mean6 + lying_mean6 + sitting_mean6 + standing_mean6 + walking_mean6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Extracting median\n",
    "bending1_median1 = []\n",
    "bending1_median2 = []\n",
    "bending1_median3 = []\n",
    "bending1_median4 = []\n",
    "bending1_median5 = []\n",
    "bending1_median6 = []\n",
    "for i in range(1,8):\n",
    "    bending1_median1.append(np.median(bending1[i].avg_rss12))\n",
    "    bending1_median2.append(np.median(bending1[i].var_rss12))\n",
    "    bending1_median3.append(np.median(bending1[i].avg_rss13))\n",
    "    bending1_median4.append(np.median(bending1[i].var_rss13))\n",
    "    bending1_median5.append(np.median(bending1[i].avg_rss23))\n",
    "    bending1_median6.append(np.median(bending1[i].var_rss23))\n",
    "\n",
    "\n",
    "bending2_median1 = []\n",
    "bending2_median2 = []\n",
    "bending2_median3 = []\n",
    "bending2_median4 = []\n",
    "bending2_median5 = []\n",
    "bending2_median6 = []\n",
    "for i in range(1,7):\n",
    "    bending2_median1.append(np.median(bending2[i].avg_rss12))\n",
    "    bending2_median2.append(np.median(bending2[i].var_rss12))\n",
    "    bending2_median3.append(np.median(bending2[i].avg_rss13))\n",
    "    bending2_median4.append(np.median(bending2[i].var_rss13))\n",
    "    bending2_median5.append(np.median(bending2[i].avg_rss23))\n",
    "    bending2_median6.append(np.median(bending2[i].var_rss23))\n",
    "\n",
    "\n",
    "cycling_median1 = []\n",
    "cycling_median2 = []\n",
    "cycling_median3 = []\n",
    "cycling_median4 = []\n",
    "cycling_median5 = []\n",
    "cycling_median6 = []\n",
    "for i in range(1,16):\n",
    "    cycling_median1.append(np.median(cycling[i].avg_rss12))\n",
    "    cycling_median2.append(np.median(cycling[i].var_rss12))\n",
    "    cycling_median3.append(np.median(cycling[i].avg_rss13))\n",
    "    cycling_median4.append(np.median(cycling[i].var_rss13))\n",
    "    cycling_median5.append(np.median(cycling[i].avg_rss23))\n",
    "    cycling_median6.append(np.median(cycling[i].var_rss23))\n",
    "\n",
    "\n",
    "lying_median1 = []\n",
    "lying_median2 = []\n",
    "lying_median3 = []\n",
    "lying_median4 = []\n",
    "lying_median5 = []\n",
    "lying_median6 = []\n",
    "for i in range(1,16):\n",
    "    lying_median1.append(np.median(lying[i].avg_rss12))\n",
    "    lying_median2.append(np.median(lying[i].var_rss12))\n",
    "    lying_median3.append(np.median(lying[i].avg_rss13))\n",
    "    lying_median4.append(np.median(lying[i].var_rss13))\n",
    "    lying_median5.append(np.median(lying[i].avg_rss23))\n",
    "    lying_median6.append(np.median(lying[i].var_rss23))\n",
    "\n",
    "\n",
    "sitting_median1 = []\n",
    "sitting_median2 = []\n",
    "sitting_median3 = []\n",
    "sitting_median4 = []\n",
    "sitting_median5 = []\n",
    "sitting_median6 = []\n",
    "for i in range(1,16):\n",
    "    sitting_median1.append(np.median(sitting[i].avg_rss12))\n",
    "    sitting_median2.append(np.median(sitting[i].var_rss12))\n",
    "    sitting_median3.append(np.median(sitting[i].avg_rss13))\n",
    "    sitting_median4.append(np.median(sitting[i].var_rss13))\n",
    "    sitting_median5.append(np.median(sitting[i].avg_rss23))\n",
    "    sitting_median6.append(np.median(sitting[i].var_rss23))\n",
    "\n",
    "\n",
    "standing_median1 = []\n",
    "standing_median2 = []\n",
    "standing_median3 = []\n",
    "standing_median4 = []\n",
    "standing_median5 = []\n",
    "standing_median6 = []\n",
    "for i in range(1,16):\n",
    "    standing_median1.append(np.median(standing[i].avg_rss12))\n",
    "    standing_median2.append(np.median(standing[i].var_rss12))\n",
    "    standing_median3.append(np.median(standing[i].avg_rss13))\n",
    "    standing_median4.append(np.median(standing[i].var_rss13))\n",
    "    standing_median5.append(np.median(standing[i].avg_rss23))\n",
    "    standing_median6.append(np.median(standing[i].var_rss23))\n",
    "\n",
    "\n",
    "walking_median1 = []\n",
    "walking_median2 = []\n",
    "walking_median3 = []\n",
    "walking_median4 = []\n",
    "walking_median5 = []\n",
    "walking_median6 = []\n",
    "for i in range(1,16):\n",
    "    walking_median1.append(np.median(walking[i].avg_rss12))\n",
    "    walking_median2.append(np.median(walking[i].var_rss12))\n",
    "    walking_median3.append(np.median(walking[i].avg_rss13))\n",
    "    walking_median4.append(np.median(walking[i].var_rss13))\n",
    "    walking_median5.append(np.median(walking[i].avg_rss23))\n",
    "    walking_median6.append(np.median(walking[i].var_rss23))\n",
    "\n",
    "\n",
    "median1 = bending1_median1 + bending2_median1 + cycling_median1 + lying_median1 + sitting_median1 + standing_median1 + walking_median1\n",
    "median2 = bending1_median2 + bending2_median2 + cycling_median2 + lying_median2 + sitting_median2 + standing_median2 + walking_median2\n",
    "median3 = bending1_median3 + bending2_median3 + cycling_median3 + lying_median3 + sitting_median3 + standing_median3 + walking_median3\n",
    "median4 = bending1_median4 + bending2_median4 + cycling_median4 + lying_median4 + sitting_median4 + standing_median4 + walking_median4\n",
    "median5 = bending1_median5 + bending2_median5 + cycling_median5 + lying_median5 + sitting_median5 + standing_median5 + walking_median5\n",
    "median6 = bending1_median6 + bending2_median6 + cycling_median6 + lying_median6 + sitting_median6 + standing_median6 + walking_median6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Extracting Standard Deviation\n",
    "bending1_std1 = []\n",
    "bending1_std2 = []\n",
    "bending1_std3 = []\n",
    "bending1_std4 = []\n",
    "bending1_std5 = []\n",
    "bending1_std6 = []\n",
    "for i in range(1,8):\n",
    "    bending1_std1.append(np.std(bending1[i].avg_rss12))\n",
    "    bending1_std2.append(np.std(bending1[i].var_rss12))\n",
    "    bending1_std3.append(np.std(bending1[i].avg_rss13))\n",
    "    bending1_std4.append(np.std(bending1[i].var_rss13))\n",
    "    bending1_std5.append(np.std(bending1[i].avg_rss23))\n",
    "    bending1_std6.append(np.std(bending1[i].var_rss23))\n",
    "\n",
    "\n",
    "bending2_std1 = []\n",
    "bending2_std2 = []\n",
    "bending2_std3 = []\n",
    "bending2_std4 = []\n",
    "bending2_std5 = []\n",
    "bending2_std6 = []\n",
    "for i in range(1,7):\n",
    "    bending2_std1.append(np.std(bending2[i].avg_rss12))\n",
    "    bending2_std2.append(np.std(bending2[i].var_rss12))\n",
    "    bending2_std3.append(np.std(bending2[i].avg_rss13))\n",
    "    bending2_std4.append(np.std(bending2[i].var_rss13))\n",
    "    bending2_std5.append(np.std(bending2[i].avg_rss23))\n",
    "    bending2_std6.append(np.std(bending2[i].var_rss23))\n",
    "\n",
    "\n",
    "cycling_std1 = []\n",
    "cycling_std2 = []\n",
    "cycling_std3 = []\n",
    "cycling_std4 = []\n",
    "cycling_std5 = []\n",
    "cycling_std6 = []\n",
    "for i in range(1,16):\n",
    "    cycling_std1.append(np.std(cycling[i].avg_rss12))\n",
    "    cycling_std2.append(np.std(cycling[i].var_rss12))\n",
    "    cycling_std3.append(np.std(cycling[i].avg_rss13))\n",
    "    cycling_std4.append(np.std(cycling[i].var_rss13))\n",
    "    cycling_std5.append(np.std(cycling[i].avg_rss23))\n",
    "    cycling_std6.append(np.std(cycling[i].var_rss23))\n",
    "\n",
    "\n",
    "lying_std1 = []\n",
    "lying_std2 = []\n",
    "lying_std3 = []\n",
    "lying_std4 = []\n",
    "lying_std5 = []\n",
    "lying_std6 = []\n",
    "for i in range(1,16):\n",
    "    lying_std1.append(np.std(lying[i].avg_rss12))\n",
    "    lying_std2.append(np.std(lying[i].var_rss12))\n",
    "    lying_std3.append(np.std(lying[i].avg_rss13))\n",
    "    lying_std4.append(np.std(lying[i].var_rss13))\n",
    "    lying_std5.append(np.std(lying[i].avg_rss23))\n",
    "    lying_std6.append(np.std(lying[i].var_rss23))\n",
    "\n",
    "\n",
    "sitting_std1 = []\n",
    "sitting_std2 = []\n",
    "sitting_std3 = []\n",
    "sitting_std4 = []\n",
    "sitting_std5 = []\n",
    "sitting_std6 = []\n",
    "for i in range(1,16):\n",
    "    sitting_std1.append(np.std(sitting[i].avg_rss12))\n",
    "    sitting_std2.append(np.std(sitting[i].var_rss12))\n",
    "    sitting_std3.append(np.std(sitting[i].avg_rss13))\n",
    "    sitting_std4.append(np.std(sitting[i].var_rss13))\n",
    "    sitting_std5.append(np.std(sitting[i].avg_rss23))\n",
    "    sitting_std6.append(np.std(sitting[i].var_rss23))\n",
    "\n",
    "\n",
    "standing_std1 = []\n",
    "standing_std2 = []\n",
    "standing_std3 = []\n",
    "standing_std4 = []\n",
    "standing_std5 = []\n",
    "standing_std6 = []\n",
    "for i in range(1,16):\n",
    "    standing_std1.append(np.std(standing[i].avg_rss12))\n",
    "    standing_std2.append(np.std(standing[i].var_rss12))\n",
    "    standing_std3.append(np.std(standing[i].avg_rss13))\n",
    "    standing_std4.append(np.std(standing[i].var_rss13))\n",
    "    standing_std5.append(np.std(standing[i].avg_rss23))\n",
    "    standing_std6.append(np.std(standing[i].var_rss23))\n",
    "\n",
    "\n",
    "walking_std1 = []\n",
    "walking_std2 = []\n",
    "walking_std3 = []\n",
    "walking_std4 = []\n",
    "walking_std5 = []\n",
    "walking_std6 = []\n",
    "for i in range(1,16):\n",
    "    walking_std1.append(np.std(walking[i].avg_rss12))\n",
    "    walking_std2.append(np.std(walking[i].var_rss12))\n",
    "    walking_std3.append(np.std(walking[i].avg_rss13))\n",
    "    walking_std4.append(np.std(walking[i].var_rss13))\n",
    "    walking_std5.append(np.std(walking[i].avg_rss23))\n",
    "    walking_std6.append(np.std(walking[i].var_rss23))\n",
    "\n",
    "\n",
    "std1 = bending1_std1 + bending2_std1 + cycling_std1 + lying_std1 + sitting_std1 + standing_std1 + walking_std1\n",
    "std2 = bending1_std2 + bending2_std2 + cycling_std2 + lying_std2 + sitting_std2 + standing_std2 + walking_std2\n",
    "std3 = bending1_std3 + bending2_std3 + cycling_std3 + lying_std3 + sitting_std3 + standing_std3 + walking_std3\n",
    "std4 = bending1_std4 + bending2_std4 + cycling_std4 + lying_std4 + sitting_std4 + standing_std4 + walking_std4\n",
    "std5 = bending1_std5 + bending2_std5 + cycling_std5 + lying_std5 + sitting_std5 + standing_std5 + walking_std5\n",
    "std6 = bending1_std6 + bending2_std6 + cycling_std6 + lying_std6 + sitting_std6 + standing_std6 + walking_std6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Extracting first quantile\n",
    "bending1_firstQuartile1 = []\n",
    "bending1_firstQuartile2 = []\n",
    "bending1_firstQuartile3 = []\n",
    "bending1_firstQuartile4 = []\n",
    "bending1_firstQuartile5 = []\n",
    "bending1_firstQuartile6 = []\n",
    "for i in range(1,8):\n",
    "    bending1_firstQuartile1.append(np.percentile(bending1[i].avg_rss12, 25))\n",
    "    bending1_firstQuartile2.append(np.percentile(bending1[i].var_rss12, 25))\n",
    "    bending1_firstQuartile3.append(np.percentile(bending1[i].avg_rss13, 25))\n",
    "    bending1_firstQuartile4.append(np.percentile(bending1[i].var_rss13, 25))\n",
    "    bending1_firstQuartile5.append(np.percentile(bending1[i].avg_rss23, 25))\n",
    "    bending1_firstQuartile6.append(np.percentile(bending1[i].var_rss23, 25))\n",
    "\n",
    "\n",
    "bending2_firstQuartile1 = []\n",
    "bending2_firstQuartile2 = []\n",
    "bending2_firstQuartile3 = []\n",
    "bending2_firstQuartile4 = []\n",
    "bending2_firstQuartile5 = []\n",
    "bending2_firstQuartile6 = []\n",
    "for i in range(1,7):\n",
    "    bending2_firstQuartile1.append(np.percentile(bending2[i].avg_rss12, 25))\n",
    "    bending2_firstQuartile2.append(np.percentile(bending2[i].var_rss12, 25))\n",
    "    bending2_firstQuartile3.append(np.percentile(bending2[i].avg_rss13, 25))\n",
    "    bending2_firstQuartile4.append(np.percentile(bending2[i].var_rss13, 25))\n",
    "    bending2_firstQuartile5.append(np.percentile(bending2[i].avg_rss23, 25))\n",
    "    bending2_firstQuartile6.append(np.percentile(bending2[i].var_rss23, 25))\n",
    "\n",
    "\n",
    "cycling_firstQuartile1 = []\n",
    "cycling_firstQuartile2 = []\n",
    "cycling_firstQuartile3 = []\n",
    "cycling_firstQuartile4 = []\n",
    "cycling_firstQuartile5 = []\n",
    "cycling_firstQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    cycling_firstQuartile1.append(np.percentile(cycling[i].avg_rss12, 25))\n",
    "    cycling_firstQuartile2.append(np.percentile(cycling[i].var_rss12, 25))\n",
    "    cycling_firstQuartile3.append(np.percentile(cycling[i].avg_rss13, 25))\n",
    "    cycling_firstQuartile4.append(np.percentile(cycling[i].var_rss13, 25))\n",
    "    cycling_firstQuartile5.append(np.percentile(cycling[i].avg_rss23, 25))\n",
    "    cycling_firstQuartile6.append(np.percentile(cycling[i].var_rss23, 25))\n",
    "\n",
    "\n",
    "lying_firstQuartile1 = []\n",
    "lying_firstQuartile2 = []\n",
    "lying_firstQuartile3 = []\n",
    "lying_firstQuartile4 = []\n",
    "lying_firstQuartile5 = []\n",
    "lying_firstQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    lying_firstQuartile1.append(np.percentile(lying[i].avg_rss12, 25))\n",
    "    lying_firstQuartile2.append(np.percentile(lying[i].var_rss12, 25))\n",
    "    lying_firstQuartile3.append(np.percentile(lying[i].avg_rss13, 25))\n",
    "    lying_firstQuartile4.append(np.percentile(lying[i].var_rss13, 25))\n",
    "    lying_firstQuartile5.append(np.percentile(lying[i].avg_rss23, 25))\n",
    "    lying_firstQuartile6.append(np.percentile(lying[i].var_rss23, 25))\n",
    "\n",
    "\n",
    "sitting_firstQuartile1 = []\n",
    "sitting_firstQuartile2 = []\n",
    "sitting_firstQuartile3 = []\n",
    "sitting_firstQuartile4 = []\n",
    "sitting_firstQuartile5 = []\n",
    "sitting_firstQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    sitting_firstQuartile1.append(np.percentile(sitting[i].avg_rss12, 25))\n",
    "    sitting_firstQuartile2.append(np.percentile(sitting[i].var_rss12, 25))\n",
    "    sitting_firstQuartile3.append(np.percentile(sitting[i].avg_rss13, 25))\n",
    "    sitting_firstQuartile4.append(np.percentile(sitting[i].var_rss13, 25))\n",
    "    sitting_firstQuartile5.append(np.percentile(sitting[i].avg_rss23, 25))\n",
    "    sitting_firstQuartile6.append(np.percentile(sitting[i].var_rss23, 25))\n",
    "\n",
    "\n",
    "standing_firstQuartile1 = []\n",
    "standing_firstQuartile2 = []\n",
    "standing_firstQuartile3 = []\n",
    "standing_firstQuartile4 = []\n",
    "standing_firstQuartile5 = []\n",
    "standing_firstQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    standing_firstQuartile1.append(np.percentile(standing[i].avg_rss12, 25))\n",
    "    standing_firstQuartile2.append(np.percentile(standing[i].var_rss12, 25))\n",
    "    standing_firstQuartile3.append(np.percentile(standing[i].avg_rss13, 25))\n",
    "    standing_firstQuartile4.append(np.percentile(standing[i].var_rss13, 25))\n",
    "    standing_firstQuartile5.append(np.percentile(standing[i].avg_rss23, 25))\n",
    "    standing_firstQuartile6.append(np.percentile(standing[i].var_rss23, 25))\n",
    "\n",
    "\n",
    "walking_firstQuartile1 = []\n",
    "walking_firstQuartile2 = []\n",
    "walking_firstQuartile3 = []\n",
    "walking_firstQuartile4 = []\n",
    "walking_firstQuartile5 = []\n",
    "walking_firstQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    walking_firstQuartile1.append(np.percentile(walking[i].avg_rss12, 25))\n",
    "    walking_firstQuartile2.append(np.percentile(walking[i].var_rss12, 25))\n",
    "    walking_firstQuartile3.append(np.percentile(walking[i].avg_rss13, 25))\n",
    "    walking_firstQuartile4.append(np.percentile(walking[i].var_rss13, 25))\n",
    "    walking_firstQuartile5.append(np.percentile(walking[i].avg_rss23, 25))\n",
    "    walking_firstQuartile6.append(np.percentile(walking[i].var_rss23, 25))\n",
    "\n",
    "\n",
    "firstQuartile1 = bending1_firstQuartile1 + bending2_firstQuartile1 + cycling_firstQuartile1 + lying_firstQuartile1 + sitting_firstQuartile1 + standing_firstQuartile1 + walking_firstQuartile1\n",
    "firstQuartile2 = bending1_firstQuartile2 + bending2_firstQuartile2 + cycling_firstQuartile2 + lying_firstQuartile2 + sitting_firstQuartile2 + standing_firstQuartile2 + walking_firstQuartile2\n",
    "firstQuartile3 = bending1_firstQuartile3 + bending2_firstQuartile3 + cycling_firstQuartile3 + lying_firstQuartile3 + sitting_firstQuartile3 + standing_firstQuartile3 + walking_firstQuartile3\n",
    "firstQuartile4 = bending1_firstQuartile4 + bending2_firstQuartile4 + cycling_firstQuartile4 + lying_firstQuartile4 + sitting_firstQuartile4 + standing_firstQuartile4 + walking_firstQuartile4\n",
    "firstQuartile5 = bending1_firstQuartile5 + bending2_firstQuartile5 + cycling_firstQuartile5 + lying_firstQuartile5 + sitting_firstQuartile5 + standing_firstQuartile5 + walking_firstQuartile5\n",
    "firstQuartile6 = bending1_firstQuartile6 + bending2_firstQuartile6 + cycling_firstQuartile6 + lying_firstQuartile6 + sitting_firstQuartile6 + standing_firstQuartile6 + walking_firstQuartile6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Extracting third quartile\n",
    "bending1_thirdQuartile1 = []\n",
    "bending1_thirdQuartile2 = []\n",
    "bending1_thirdQuartile3 = []\n",
    "bending1_thirdQuartile4 = []\n",
    "bending1_thirdQuartile5 = []\n",
    "bending1_thirdQuartile6 = []\n",
    "for i in range(1,8):\n",
    "    bending1_thirdQuartile1.append(np.percentile(bending1[i].avg_rss12, 75))\n",
    "    bending1_thirdQuartile2.append(np.percentile(bending1[i].var_rss12, 75))\n",
    "    bending1_thirdQuartile3.append(np.percentile(bending1[i].avg_rss13, 75))\n",
    "    bending1_thirdQuartile4.append(np.percentile(bending1[i].var_rss13, 75))\n",
    "    bending1_thirdQuartile5.append(np.percentile(bending1[i].avg_rss23, 75))\n",
    "    bending1_thirdQuartile6.append(np.percentile(bending1[i].var_rss23, 75))\n",
    "\n",
    "\n",
    "bending2_thirdQuartile1 = []\n",
    "bending2_thirdQuartile2 = []\n",
    "bending2_thirdQuartile3 = []\n",
    "bending2_thirdQuartile4 = []\n",
    "bending2_thirdQuartile5 = []\n",
    "bending2_thirdQuartile6 = []\n",
    "for i in range(1,7):\n",
    "    bending2_thirdQuartile1.append(np.percentile(bending2[i].avg_rss12, 75))\n",
    "    bending2_thirdQuartile2.append(np.percentile(bending2[i].var_rss12, 75))\n",
    "    bending2_thirdQuartile3.append(np.percentile(bending2[i].avg_rss13, 75))\n",
    "    bending2_thirdQuartile4.append(np.percentile(bending2[i].var_rss13, 75))\n",
    "    bending2_thirdQuartile5.append(np.percentile(bending2[i].avg_rss23, 75))\n",
    "    bending2_thirdQuartile6.append(np.percentile(bending2[i].var_rss23, 75))\n",
    "\n",
    "\n",
    "cycling_thirdQuartile1 = []\n",
    "cycling_thirdQuartile2 = []\n",
    "cycling_thirdQuartile3 = []\n",
    "cycling_thirdQuartile4 = []\n",
    "cycling_thirdQuartile5 = []\n",
    "cycling_thirdQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    cycling_thirdQuartile1.append(np.percentile(cycling[i].avg_rss12, 75))\n",
    "    cycling_thirdQuartile2.append(np.percentile(cycling[i].var_rss12, 75))\n",
    "    cycling_thirdQuartile3.append(np.percentile(cycling[i].avg_rss13, 75))\n",
    "    cycling_thirdQuartile4.append(np.percentile(cycling[i].var_rss13, 75))\n",
    "    cycling_thirdQuartile5.append(np.percentile(cycling[i].avg_rss23, 75))\n",
    "    cycling_thirdQuartile6.append(np.percentile(cycling[i].var_rss23, 75))\n",
    "\n",
    "\n",
    "lying_thirdQuartile1 = []\n",
    "lying_thirdQuartile2 = []\n",
    "lying_thirdQuartile3 = []\n",
    "lying_thirdQuartile4 = []\n",
    "lying_thirdQuartile5 = []\n",
    "lying_thirdQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    lying_thirdQuartile1.append(np.percentile(lying[i].avg_rss12, 75))\n",
    "    lying_thirdQuartile2.append(np.percentile(lying[i].var_rss12, 75))\n",
    "    lying_thirdQuartile3.append(np.percentile(lying[i].avg_rss13, 75))\n",
    "    lying_thirdQuartile4.append(np.percentile(lying[i].var_rss13, 75))\n",
    "    lying_thirdQuartile5.append(np.percentile(lying[i].avg_rss23, 75))\n",
    "    lying_thirdQuartile6.append(np.percentile(lying[i].var_rss23, 75))\n",
    "\n",
    "\n",
    "sitting_thirdQuartile1 = []\n",
    "sitting_thirdQuartile2 = []\n",
    "sitting_thirdQuartile3 = []\n",
    "sitting_thirdQuartile4 = []\n",
    "sitting_thirdQuartile5 = []\n",
    "sitting_thirdQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    sitting_thirdQuartile1.append(np.percentile(sitting[i].avg_rss12, 75))\n",
    "    sitting_thirdQuartile2.append(np.percentile(sitting[i].var_rss12, 75))\n",
    "    sitting_thirdQuartile3.append(np.percentile(sitting[i].avg_rss13, 75))\n",
    "    sitting_thirdQuartile4.append(np.percentile(sitting[i].var_rss13, 75))\n",
    "    sitting_thirdQuartile5.append(np.percentile(sitting[i].avg_rss23, 75))\n",
    "    sitting_thirdQuartile6.append(np.percentile(sitting[i].var_rss23, 75))\n",
    "\n",
    "\n",
    "standing_thirdQuartile1 = []\n",
    "standing_thirdQuartile2 = []\n",
    "standing_thirdQuartile3 = []\n",
    "standing_thirdQuartile4 = []\n",
    "standing_thirdQuartile5 = []\n",
    "standing_thirdQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    standing_thirdQuartile1.append(np.percentile(standing[i].avg_rss12, 75))\n",
    "    standing_thirdQuartile2.append(np.percentile(standing[i].var_rss12, 75))\n",
    "    standing_thirdQuartile3.append(np.percentile(standing[i].avg_rss13, 75))\n",
    "    standing_thirdQuartile4.append(np.percentile(standing[i].var_rss13, 75))\n",
    "    standing_thirdQuartile5.append(np.percentile(standing[i].avg_rss23, 75))\n",
    "    standing_thirdQuartile6.append(np.percentile(standing[i].var_rss23, 75))\n",
    "\n",
    "\n",
    "walking_thirdQuartile1 = []\n",
    "walking_thirdQuartile2 = []\n",
    "walking_thirdQuartile3 = []\n",
    "walking_thirdQuartile4 = []\n",
    "walking_thirdQuartile5 = []\n",
    "walking_thirdQuartile6 = []\n",
    "for i in range(1,16):\n",
    "    walking_thirdQuartile1.append(np.percentile(walking[i].avg_rss12, 75))\n",
    "    walking_thirdQuartile2.append(np.percentile(walking[i].var_rss12, 75))\n",
    "    walking_thirdQuartile3.append(np.percentile(walking[i].avg_rss13, 75))\n",
    "    walking_thirdQuartile4.append(np.percentile(walking[i].var_rss13, 75))\n",
    "    walking_thirdQuartile5.append(np.percentile(walking[i].avg_rss23, 75))\n",
    "    walking_thirdQuartile6.append(np.percentile(walking[i].var_rss23, 75))\n",
    "\n",
    "\n",
    "thirdQuartile1 = bending1_thirdQuartile1 + bending2_thirdQuartile1 + cycling_thirdQuartile1 + lying_thirdQuartile1 + sitting_thirdQuartile1 + standing_thirdQuartile1 + walking_thirdQuartile1\n",
    "thirdQuartile2 = bending1_thirdQuartile2 + bending2_thirdQuartile2 + cycling_thirdQuartile2 + lying_thirdQuartile2 + sitting_thirdQuartile2 + standing_thirdQuartile2 + walking_thirdQuartile2\n",
    "thirdQuartile3 = bending1_thirdQuartile3 + bending2_thirdQuartile3 + cycling_thirdQuartile3 + lying_thirdQuartile3 + sitting_thirdQuartile3 + standing_thirdQuartile3 + walking_thirdQuartile3\n",
    "thirdQuartile4 = bending1_thirdQuartile4 + bending2_thirdQuartile4 + cycling_thirdQuartile4 + lying_thirdQuartile4 + sitting_thirdQuartile4 + standing_thirdQuartile4 + walking_thirdQuartile4\n",
    "thirdQuartile5 = bending1_thirdQuartile5 + bending2_thirdQuartile5 + cycling_thirdQuartile5 + lying_thirdQuartile5 + sitting_thirdQuartile5 + standing_thirdQuartile5 + walking_thirdQuartile5\n",
    "thirdQuartile6 = bending1_thirdQuartile6 + bending2_thirdQuartile6 + cycling_thirdQuartile6 + lying_thirdQuartile6 + sitting_thirdQuartile6 + standing_thirdQuartile6 + walking_thirdQuartile6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "instance=[]\n",
    "for i in range(1,89):\n",
    "    instance.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "    Instance   min1  min2  min3  min4   min5  min6   max1   max2   max3  ...  \\\n0        1.0  37.25   0.0  4.00   0.0  27.25  0.00  45.00   1.30  29.50  ...   \n1        2.0  38.00   0.0  2.00   0.0  27.67  0.00  45.67   1.22  29.50  ...   \n2        3.0  35.00   0.0  6.50   0.0  29.00  0.00  47.40   1.70  29.75  ...   \n3        4.0  33.00   0.0  8.50   0.0  20.00  0.00  47.75   3.00  30.00  ...   \n4        5.0  33.00   0.0  3.00   0.0  23.67  0.00  45.75   2.83  28.25  ...   \n..       ...    ...   ...   ...   ...    ...   ...    ...    ...    ...  ...   \n83      84.0  19.50   0.0  7.33   0.0   6.33  0.00  45.33  14.67  23.25  ...   \n84      85.0  19.75   0.0  6.25   0.0   6.25  0.00  45.50  13.47  22.25  ...   \n85      86.0  19.50   0.0  7.00   0.0   7.00  0.00  46.00  12.47  22.67  ...   \n86      87.0  23.50   0.0  6.67   0.0   5.50  0.00  46.25  14.82  24.25  ...   \n87      88.0  19.25   0.0  6.00   0.0   4.67  0.43  44.00  13.86  22.75  ...   \n\n    1st quart3  1st quart4  1st quart5  1st quart6  3rd quart1  3rd quart2  \\\n0        16.00      0.0000     33.0000      0.0000     42.0000      0.5000   \n1        19.00      0.0000     32.0000      0.0000     43.6700      0.5000   \n2        19.75      0.0000     35.3625      0.0000     45.0000      0.5000   \n3        20.50      0.4300     30.4575      0.0000     45.0000      1.1200   \n4        16.50      0.4300     28.4575      0.0000     42.7500      0.7100   \n..         ...         ...         ...         ...         ...         ...   \n83       13.25      2.0500     13.7300      2.0500     37.0000      6.1050   \n84       13.50      2.1700     13.5000      2.1575     38.0000      5.9700   \n85       13.25      1.7900     14.0000      2.1600     37.8125      5.8000   \n86       13.50      2.0575     13.7500      2.1700     38.2500      5.9325   \n87       13.67      2.0500     13.7300      2.1200     38.0000      5.9000   \n\n    3rd quart3  3rd quart4  3rd quart5  3rd quart6  \n0      23.2500      1.1200       36.00      1.3000  \n1      22.2500      1.1450       34.50      1.3000  \n2      24.0000      0.8300       36.50      0.9400  \n3      24.3725      1.3000       36.33      1.0000  \n4      22.0625      1.1200       31.25      0.5000  \n..         ...         ...         ...         ...  \n83     17.2700      4.2600       18.25      4.3225  \n84     17.0000      4.3900       17.75      4.5650  \n85     17.0000      4.1100       17.75      4.3350  \n86     17.2500      4.1900       18.00      4.5000  \n87     17.3300      4.0375       17.75      4.3750  \n\n[88 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Instance</th>\n      <th>min1</th>\n      <th>min2</th>\n      <th>min3</th>\n      <th>min4</th>\n      <th>min5</th>\n      <th>min6</th>\n      <th>max1</th>\n      <th>max2</th>\n      <th>max3</th>\n      <th>...</th>\n      <th>1st quart3</th>\n      <th>1st quart4</th>\n      <th>1st quart5</th>\n      <th>1st quart6</th>\n      <th>3rd quart1</th>\n      <th>3rd quart2</th>\n      <th>3rd quart3</th>\n      <th>3rd quart4</th>\n      <th>3rd quart5</th>\n      <th>3rd quart6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>37.25</td>\n      <td>0.0</td>\n      <td>4.00</td>\n      <td>0.0</td>\n      <td>27.25</td>\n      <td>0.00</td>\n      <td>45.00</td>\n      <td>1.30</td>\n      <td>29.50</td>\n      <td>...</td>\n      <td>16.00</td>\n      <td>0.0000</td>\n      <td>33.0000</td>\n      <td>0.0000</td>\n      <td>42.0000</td>\n      <td>0.5000</td>\n      <td>23.2500</td>\n      <td>1.1200</td>\n      <td>36.00</td>\n      <td>1.3000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>38.00</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>0.0</td>\n      <td>27.67</td>\n      <td>0.00</td>\n      <td>45.67</td>\n      <td>1.22</td>\n      <td>29.50</td>\n      <td>...</td>\n      <td>19.00</td>\n      <td>0.0000</td>\n      <td>32.0000</td>\n      <td>0.0000</td>\n      <td>43.6700</td>\n      <td>0.5000</td>\n      <td>22.2500</td>\n      <td>1.1450</td>\n      <td>34.50</td>\n      <td>1.3000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>35.00</td>\n      <td>0.0</td>\n      <td>6.50</td>\n      <td>0.0</td>\n      <td>29.00</td>\n      <td>0.00</td>\n      <td>47.40</td>\n      <td>1.70</td>\n      <td>29.75</td>\n      <td>...</td>\n      <td>19.75</td>\n      <td>0.0000</td>\n      <td>35.3625</td>\n      <td>0.0000</td>\n      <td>45.0000</td>\n      <td>0.5000</td>\n      <td>24.0000</td>\n      <td>0.8300</td>\n      <td>36.50</td>\n      <td>0.9400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>33.00</td>\n      <td>0.0</td>\n      <td>8.50</td>\n      <td>0.0</td>\n      <td>20.00</td>\n      <td>0.00</td>\n      <td>47.75</td>\n      <td>3.00</td>\n      <td>30.00</td>\n      <td>...</td>\n      <td>20.50</td>\n      <td>0.4300</td>\n      <td>30.4575</td>\n      <td>0.0000</td>\n      <td>45.0000</td>\n      <td>1.1200</td>\n      <td>24.3725</td>\n      <td>1.3000</td>\n      <td>36.33</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>33.00</td>\n      <td>0.0</td>\n      <td>3.00</td>\n      <td>0.0</td>\n      <td>23.67</td>\n      <td>0.00</td>\n      <td>45.75</td>\n      <td>2.83</td>\n      <td>28.25</td>\n      <td>...</td>\n      <td>16.50</td>\n      <td>0.4300</td>\n      <td>28.4575</td>\n      <td>0.0000</td>\n      <td>42.7500</td>\n      <td>0.7100</td>\n      <td>22.0625</td>\n      <td>1.1200</td>\n      <td>31.25</td>\n      <td>0.5000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>84.0</td>\n      <td>19.50</td>\n      <td>0.0</td>\n      <td>7.33</td>\n      <td>0.0</td>\n      <td>6.33</td>\n      <td>0.00</td>\n      <td>45.33</td>\n      <td>14.67</td>\n      <td>23.25</td>\n      <td>...</td>\n      <td>13.25</td>\n      <td>2.0500</td>\n      <td>13.7300</td>\n      <td>2.0500</td>\n      <td>37.0000</td>\n      <td>6.1050</td>\n      <td>17.2700</td>\n      <td>4.2600</td>\n      <td>18.25</td>\n      <td>4.3225</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>85.0</td>\n      <td>19.75</td>\n      <td>0.0</td>\n      <td>6.25</td>\n      <td>0.0</td>\n      <td>6.25</td>\n      <td>0.00</td>\n      <td>45.50</td>\n      <td>13.47</td>\n      <td>22.25</td>\n      <td>...</td>\n      <td>13.50</td>\n      <td>2.1700</td>\n      <td>13.5000</td>\n      <td>2.1575</td>\n      <td>38.0000</td>\n      <td>5.9700</td>\n      <td>17.0000</td>\n      <td>4.3900</td>\n      <td>17.75</td>\n      <td>4.5650</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>86.0</td>\n      <td>19.50</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>0.00</td>\n      <td>46.00</td>\n      <td>12.47</td>\n      <td>22.67</td>\n      <td>...</td>\n      <td>13.25</td>\n      <td>1.7900</td>\n      <td>14.0000</td>\n      <td>2.1600</td>\n      <td>37.8125</td>\n      <td>5.8000</td>\n      <td>17.0000</td>\n      <td>4.1100</td>\n      <td>17.75</td>\n      <td>4.3350</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>87.0</td>\n      <td>23.50</td>\n      <td>0.0</td>\n      <td>6.67</td>\n      <td>0.0</td>\n      <td>5.50</td>\n      <td>0.00</td>\n      <td>46.25</td>\n      <td>14.82</td>\n      <td>24.25</td>\n      <td>...</td>\n      <td>13.50</td>\n      <td>2.0575</td>\n      <td>13.7500</td>\n      <td>2.1700</td>\n      <td>38.2500</td>\n      <td>5.9325</td>\n      <td>17.2500</td>\n      <td>4.1900</td>\n      <td>18.00</td>\n      <td>4.5000</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>88.0</td>\n      <td>19.25</td>\n      <td>0.0</td>\n      <td>6.00</td>\n      <td>0.0</td>\n      <td>4.67</td>\n      <td>0.43</td>\n      <td>44.00</td>\n      <td>13.86</td>\n      <td>22.75</td>\n      <td>...</td>\n      <td>13.67</td>\n      <td>2.0500</td>\n      <td>13.7300</td>\n      <td>2.1200</td>\n      <td>38.0000</td>\n      <td>5.9000</td>\n      <td>17.3300</td>\n      <td>4.0375</td>\n      <td>17.75</td>\n      <td>4.3750</td>\n    </tr>\n  </tbody>\n</table>\n<p>88 rows  43 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [instance, min1, min2, min3, min4, min5, min6, max1, max2, max3, max4, max5, max6, mean1, mean2, mean3, mean4, mean5, mean6, median1, median2, median3, median4, median5, median6, std1, std2, std3, std4, std5, std6, firstQuartile1, firstQuartile2, firstQuartile3, firstQuartile4, firstQuartile5, firstQuartile6, thirdQuartile1, thirdQuartile2, thirdQuartile3, thirdQuartile4, thirdQuartile5, thirdQuartile6]\n",
    "\n",
    "table = pd.DataFrame(data)\n",
    "table = table.transpose()\n",
    "table.columns = ['Instance', 'min1', 'min2', 'min3', 'min4', 'min5', 'min6', 'max1', 'max2', 'max3', 'max4', 'max5', 'max6', 'mean1', 'mean2', 'mean3', 'mean4', 'mean5', 'mean6', 'median1', 'median2', 'median3', 'median4', 'median5', 'median6', 'std1', 'std2', 'std3', 'std4', 'std5', 'std6', '1st quart1', '1st quart2', '1st quart3', '1st quart4', '1st quart5', '1st quart6', '3rd quart1', '3rd quart2', '3rd quart3', '3rd quart4', '3rd quart5', '3rd quart6']\n",
    "\n",
    "table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "        min1  min2      min3  min4      min5      min6      max1      max2  \\\n0   0.266702   0.0  0.028639   0.0  0.195104  0.000000  0.322191  0.009308   \n1   0.267837   0.0  0.014097   0.0  0.195028  0.000000  0.321898  0.008599   \n2   0.237769   0.0  0.044157   0.0  0.197008  0.000000  0.322007  0.011549   \n3   0.232260   0.0  0.059825   0.0  0.140764  0.000000  0.336074  0.021115   \n4   0.245147   0.0  0.022286   0.0  0.175837  0.000000  0.339863  0.021023   \n..       ...   ...       ...   ...       ...       ...       ...       ...   \n83  0.187280   0.0  0.070398   0.0  0.060794  0.000000  0.435354  0.140892   \n84  0.189185   0.0  0.059869   0.0  0.059869  0.000000  0.435844  0.129029   \n85  0.186469   0.0  0.066937   0.0  0.066937  0.000000  0.439875  0.119244   \n86  0.219725   0.0  0.062365   0.0  0.051425  0.000000  0.432438  0.138567   \n87  0.185269   0.0  0.057746   0.0  0.044946  0.004138  0.423471  0.133393   \n\n        max3      max4  ...  1st quart3  1st quart4  1st quart5  1st quart6  \\\n0   0.211214  0.051765  ...    0.114557    0.000000    0.236273    0.000000   \n1   0.207926  0.040598  ...    0.133919    0.000000    0.225547    0.000000   \n2   0.202103  0.030163  ...    0.134170    0.000000    0.240231    0.000000   \n3   0.211146  0.036247  ...    0.144283    0.003026    0.214366    0.000000   \n4   0.209861  0.047692  ...    0.122574    0.003194    0.211402    0.000000   \n..       ...       ...  ...         ...         ...         ...         ...   \n83  0.223296  0.086437  ...    0.127255    0.019688    0.131864    0.019688   \n84  0.213132  0.086211  ...    0.129316    0.020786    0.129316    0.020667   \n85  0.216782  0.079751  ...    0.126703    0.017117    0.133875    0.020655   \n86  0.226738  0.092565  ...    0.126225    0.019238    0.128563    0.020290   \n87  0.218954  0.087581  ...    0.131565    0.019730    0.132142    0.020404   \n\n    3rd quart1  3rd quart2  3rd quart3  3rd quart4  3rd quart5  3rd quart6  \n0     0.300711    0.003580    0.166465    0.008019    0.257753    0.009308  \n1     0.307801    0.003524    0.156826    0.008070    0.243168    0.009163  \n2     0.305703    0.003397    0.163041    0.005639    0.247959    0.006386  \n3     0.316719    0.007883    0.171538    0.009150    0.255698    0.007038  \n4     0.317577    0.005274    0.163896    0.008320    0.232147    0.003714  \n..         ...         ...         ...         ...         ...         ...  \n83    0.355352    0.058633    0.165863    0.040914    0.175275    0.041514  \n84    0.364001    0.057187    0.162843    0.042052    0.170027    0.043728  \n85    0.361582    0.055462    0.162562    0.039302    0.169734    0.041453  \n86    0.357638    0.055469    0.161288    0.039177    0.168300    0.042075  \n87    0.365725    0.056784    0.166790    0.038858    0.170832    0.042106  \n\n[88 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min1</th>\n      <th>min2</th>\n      <th>min3</th>\n      <th>min4</th>\n      <th>min5</th>\n      <th>min6</th>\n      <th>max1</th>\n      <th>max2</th>\n      <th>max3</th>\n      <th>max4</th>\n      <th>...</th>\n      <th>1st quart3</th>\n      <th>1st quart4</th>\n      <th>1st quart5</th>\n      <th>1st quart6</th>\n      <th>3rd quart1</th>\n      <th>3rd quart2</th>\n      <th>3rd quart3</th>\n      <th>3rd quart4</th>\n      <th>3rd quart5</th>\n      <th>3rd quart6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.266702</td>\n      <td>0.0</td>\n      <td>0.028639</td>\n      <td>0.0</td>\n      <td>0.195104</td>\n      <td>0.000000</td>\n      <td>0.322191</td>\n      <td>0.009308</td>\n      <td>0.211214</td>\n      <td>0.051765</td>\n      <td>...</td>\n      <td>0.114557</td>\n      <td>0.000000</td>\n      <td>0.236273</td>\n      <td>0.000000</td>\n      <td>0.300711</td>\n      <td>0.003580</td>\n      <td>0.166465</td>\n      <td>0.008019</td>\n      <td>0.257753</td>\n      <td>0.009308</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.267837</td>\n      <td>0.0</td>\n      <td>0.014097</td>\n      <td>0.0</td>\n      <td>0.195028</td>\n      <td>0.000000</td>\n      <td>0.321898</td>\n      <td>0.008599</td>\n      <td>0.207926</td>\n      <td>0.040598</td>\n      <td>...</td>\n      <td>0.133919</td>\n      <td>0.000000</td>\n      <td>0.225547</td>\n      <td>0.000000</td>\n      <td>0.307801</td>\n      <td>0.003524</td>\n      <td>0.156826</td>\n      <td>0.008070</td>\n      <td>0.243168</td>\n      <td>0.009163</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.237769</td>\n      <td>0.0</td>\n      <td>0.044157</td>\n      <td>0.0</td>\n      <td>0.197008</td>\n      <td>0.000000</td>\n      <td>0.322007</td>\n      <td>0.011549</td>\n      <td>0.202103</td>\n      <td>0.030163</td>\n      <td>...</td>\n      <td>0.134170</td>\n      <td>0.000000</td>\n      <td>0.240231</td>\n      <td>0.000000</td>\n      <td>0.305703</td>\n      <td>0.003397</td>\n      <td>0.163041</td>\n      <td>0.005639</td>\n      <td>0.247959</td>\n      <td>0.006386</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.232260</td>\n      <td>0.0</td>\n      <td>0.059825</td>\n      <td>0.0</td>\n      <td>0.140764</td>\n      <td>0.000000</td>\n      <td>0.336074</td>\n      <td>0.021115</td>\n      <td>0.211146</td>\n      <td>0.036247</td>\n      <td>...</td>\n      <td>0.144283</td>\n      <td>0.003026</td>\n      <td>0.214366</td>\n      <td>0.000000</td>\n      <td>0.316719</td>\n      <td>0.007883</td>\n      <td>0.171538</td>\n      <td>0.009150</td>\n      <td>0.255698</td>\n      <td>0.007038</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.245147</td>\n      <td>0.0</td>\n      <td>0.022286</td>\n      <td>0.0</td>\n      <td>0.175837</td>\n      <td>0.000000</td>\n      <td>0.339863</td>\n      <td>0.021023</td>\n      <td>0.209861</td>\n      <td>0.047692</td>\n      <td>...</td>\n      <td>0.122574</td>\n      <td>0.003194</td>\n      <td>0.211402</td>\n      <td>0.000000</td>\n      <td>0.317577</td>\n      <td>0.005274</td>\n      <td>0.163896</td>\n      <td>0.008320</td>\n      <td>0.232147</td>\n      <td>0.003714</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>0.187280</td>\n      <td>0.0</td>\n      <td>0.070398</td>\n      <td>0.0</td>\n      <td>0.060794</td>\n      <td>0.000000</td>\n      <td>0.435354</td>\n      <td>0.140892</td>\n      <td>0.223296</td>\n      <td>0.086437</td>\n      <td>...</td>\n      <td>0.127255</td>\n      <td>0.019688</td>\n      <td>0.131864</td>\n      <td>0.019688</td>\n      <td>0.355352</td>\n      <td>0.058633</td>\n      <td>0.165863</td>\n      <td>0.040914</td>\n      <td>0.175275</td>\n      <td>0.041514</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>0.189185</td>\n      <td>0.0</td>\n      <td>0.059869</td>\n      <td>0.0</td>\n      <td>0.059869</td>\n      <td>0.000000</td>\n      <td>0.435844</td>\n      <td>0.129029</td>\n      <td>0.213132</td>\n      <td>0.086211</td>\n      <td>...</td>\n      <td>0.129316</td>\n      <td>0.020786</td>\n      <td>0.129316</td>\n      <td>0.020667</td>\n      <td>0.364001</td>\n      <td>0.057187</td>\n      <td>0.162843</td>\n      <td>0.042052</td>\n      <td>0.170027</td>\n      <td>0.043728</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>0.186469</td>\n      <td>0.0</td>\n      <td>0.066937</td>\n      <td>0.0</td>\n      <td>0.066937</td>\n      <td>0.000000</td>\n      <td>0.439875</td>\n      <td>0.119244</td>\n      <td>0.216782</td>\n      <td>0.079751</td>\n      <td>...</td>\n      <td>0.126703</td>\n      <td>0.017117</td>\n      <td>0.133875</td>\n      <td>0.020655</td>\n      <td>0.361582</td>\n      <td>0.055462</td>\n      <td>0.162562</td>\n      <td>0.039302</td>\n      <td>0.169734</td>\n      <td>0.041453</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>0.219725</td>\n      <td>0.0</td>\n      <td>0.062365</td>\n      <td>0.0</td>\n      <td>0.051425</td>\n      <td>0.000000</td>\n      <td>0.432438</td>\n      <td>0.138567</td>\n      <td>0.226738</td>\n      <td>0.092565</td>\n      <td>...</td>\n      <td>0.126225</td>\n      <td>0.019238</td>\n      <td>0.128563</td>\n      <td>0.020290</td>\n      <td>0.357638</td>\n      <td>0.055469</td>\n      <td>0.161288</td>\n      <td>0.039177</td>\n      <td>0.168300</td>\n      <td>0.042075</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>0.185269</td>\n      <td>0.0</td>\n      <td>0.057746</td>\n      <td>0.0</td>\n      <td>0.044946</td>\n      <td>0.004138</td>\n      <td>0.423471</td>\n      <td>0.133393</td>\n      <td>0.218954</td>\n      <td>0.087581</td>\n      <td>...</td>\n      <td>0.131565</td>\n      <td>0.019730</td>\n      <td>0.132142</td>\n      <td>0.020404</td>\n      <td>0.365725</td>\n      <td>0.056784</td>\n      <td>0.166790</td>\n      <td>0.038858</td>\n      <td>0.170832</td>\n      <td>0.042106</td>\n    </tr>\n  </tbody>\n</table>\n<p>88 rows  42 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized dataframe\n",
    "table = pd.DataFrame(table).fillna(0)  # Removed NaN values\n",
    "\n",
    "scaled_data = preprocessing.normalize(table.loc[:, table.columns!='Instance'])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['min1', 'min2', 'min3', 'min4', 'min5', 'min6', 'max1', 'max2', 'max3', 'max4', 'max5', 'max6', 'mean1', 'mean2', 'mean3', 'mean4', 'mean5', 'mean6', 'median1', 'median2', 'median3', 'median4', 'median5', 'median6', 'std1', 'std2', 'std3', 'std4', 'std5', 'std6', '1st quart1', '1st quart2', '1st quart3', '1st quart4', '1st quart5', '1st quart6', '3rd quart1', '3rd quart2', '3rd quart3', '3rd quart4', '3rd quart5', '3rd quart6'])\n",
    "scaled_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1 (c) iii. Estimate the standard deviation of each of the time-domain features you extracted from the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'std_min1': 10.000011445628777,\n 'std_min2': 0.0,\n 'std_min3': 2.93961598441822,\n 'std_min4': 0.0,\n 'std_min5': 6.070888279661571,\n 'std_min6': 0.045576965827593074,\n 'std_max1': 6.378099577666058,\n 'std_max2': 5.046922737601417,\n 'std_max3': 5.347686932390445,\n 'std_max4': 2.2737070359731675,\n 'std_max5': 6.263039241230256,\n 'std_max6': 2.5965428158466395,\n 'std_mean1': 6.656895541633325,\n 'std_mean2': 1.5676674408513378,\n 'std_mean3': 4.215221888244065,\n 'std_mean4': 1.1659996868527878,\n 'std_mean5': 5.888677391044952,\n 'std_mean6': 1.1569883367590628,\n 'std_median1': 6.738516700416903,\n 'std_median2': 1.4041971241720508,\n 'std_median3': 4.258345045644309,\n 'std_median4': 1.1440906819423153,\n 'std_median5': 6.0279176495663505,\n 'std_median6': 1.0883677296546022,\n 'std_std1': 1.7780097801362074,\n 'std_std2': 0.8811669037969613,\n 'std_std3': 1.0136869214993915,\n 'std_std4': 0.46690478740322905,\n 'std_std5': 1.0683835555441004,\n 'std_std6': 0.5226066907204563,\n 'std_firstQuartile1': 7.222906491595873,\n 'std_firstQuartile2': 0.9409936333203216,\n 'std_firstQuartile3': 4.333324436444565,\n 'std_firstQuartile4': 0.8388126951078968,\n 'std_firstQuartile5': 6.226177368983006,\n 'std_firstQuartile6': 0.7589510106651274,\n 'std_thirdQuartile1': 6.627197643208146,\n 'std_thirdQuartile2': 2.1175457210064397,\n 'std_thirdQuartile3': 4.47534148391997,\n 'std_thirdQuartile4': 1.5522053998026988,\n 'std_thirdQuartile5': 5.8398742035504645,\n 'std_thirdQuartile6': 1.5266284025401033}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_of_time_domain_features = {\n",
    "    \"std_min1\" : np.std(table.min1),\n",
    "    \"std_min2\" : np.std(table.min2),\n",
    "    \"std_min3\" : np.std(table.min3),\n",
    "    \"std_min4\" : np.std(table.min4),\n",
    "    \"std_min5\" : np.std(table.min5),\n",
    "    \"std_min6\" : np.std(table.min6),\n",
    "\n",
    "    \"std_max1\" : np.std(table.max1),\n",
    "    \"std_max2\" : np.std(table.max2),\n",
    "    \"std_max3\" : np.std(table.max3),\n",
    "    \"std_max4\" : np.std(table.max4),\n",
    "    \"std_max5\" : np.std(table.max5),\n",
    "    \"std_max6\" : np.std(table.max6),\n",
    "\n",
    "    \"std_mean1\" : np.std(table.mean1),\n",
    "    \"std_mean2\" : np.std(table.mean2),\n",
    "    \"std_mean3\" : np.std(table.mean3),\n",
    "    \"std_mean4\" : np.std(table.mean4),\n",
    "    \"std_mean5\" : np.std(table.mean5),\n",
    "    \"std_mean6\" : np.std(table.mean6),\n",
    "\n",
    "    \"std_median1\" : np.std(table.median1),\n",
    "    \"std_median2\" : np.std(table.median2),\n",
    "    \"std_median3\" : np.std(table.median3),\n",
    "    \"std_median4\" : np.std(table.median4),\n",
    "    \"std_median5\" : np.std(table.median5),\n",
    "    \"std_median6\" : np.std(table.median6),\n",
    "\n",
    "    \"std_std1\" : np.std(table.std1),\n",
    "    \"std_std2\" : np.std(table.std2),\n",
    "    \"std_std3\" : np.std(table.std3),\n",
    "    \"std_std4\" : np.std(table.std4),\n",
    "    \"std_std5\" : np.std(table.std5),\n",
    "    \"std_std6\" : np.std(table.std6),\n",
    "\n",
    "    \"std_firstQuartile1\" : np.std(table['1st quart1']),\n",
    "    \"std_firstQuartile2\" : np.std(table['1st quart2']),\n",
    "    \"std_firstQuartile3\" : np.std(table['1st quart3']),\n",
    "    \"std_firstQuartile4\" : np.std(table['1st quart4']),\n",
    "    \"std_firstQuartile5\" : np.std(table['1st quart5']),\n",
    "    \"std_firstQuartile6\" : np.std(table['1st quart6']),\n",
    "\n",
    "    \"std_thirdQuartile1\" : np.std(table['3rd quart1']),\n",
    "    \"std_thirdQuartile2\" : np.std(table['3rd quart2']),\n",
    "    \"std_thirdQuartile3\" : np.std(table['3rd quart3']),\n",
    "    \"std_thirdQuartile4\" : np.std(table['3rd quart4']),\n",
    "    \"std_thirdQuartile5\" : np.std(table['3rd quart5']),\n",
    "    \"std_thirdQuartile6\" : np.std(table['3rd quart6'])\n",
    "}\n",
    "\n",
    "std_of_time_domain_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1 (c) iii. Use Pythons bootstrapped or any other method to build a 90% bootstrap confidence interval for the standard deviation of each feature."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bs_min1': 10.00001144562878    (8.702605318392948, 11.403108964408759),\n 'bs_min2': 0.0    (0.0, 0.0),\n 'bs_min3': 2.9396159844182215    (2.7903274553309476, 3.1360839088850874),\n 'bs_min4': 0.0    (0.0, 0.0),\n 'bs_min5': 6.070888279661571    (4.640794330354703, 7.828630256078251),\n 'bs_min6': 0.045576965827593074    (0.013124961748951322, 0.09115393165518615),\n 'bs_max1': 6.37809957766606    (3.552737264152894, 9.302318782151776),\n 'bs_max2': 5.046922737601417    (4.709378548649997, 5.490193451222369),\n 'bs_max3': 5.3476869323904435    (4.368515980355216, 6.386113797991035),\n 'bs_max4': 2.273707035973167    (2.031826823591812, 2.5285548804502564),\n 'bs_max5': 6.263039241230258    (5.178111560593315, 7.512753260630793),\n 'bs_max6': 2.596542815846639    (2.3359019464732143, 2.8851445618834832),\n 'bs_mean1': 6.6568955416333235    (4.611149700286022, 8.49970617163866),\n 'bs_mean2': 1.5676674408513378    (1.4351832873114447, 1.7441966595750338),\n 'bs_mean3': 4.2152218882440655    (3.626447015833829, 4.919798989698446),\n 'bs_mean4': 1.1659996868527878    (1.1096552058575875, 1.257765746120256),\n 'bs_mean5': 5.888677391044952    (4.80467686307828, 7.160671806801091),\n 'bs_mean6': 1.1569883367590628    (1.0948711819809767, 1.2510472787733566),\n 'bs_median1': 6.738516700416904    (4.6631129303854575, 8.564991435762277),\n 'bs_median2': 1.4041971241720508    (1.2740854463093083, 1.5742924740076736),\n 'bs_median3': 4.258345045644309    (3.65484846949754, 4.969613620909611),\n 'bs_median4': 1.144090681942315    (1.087649670760938, 1.2341906601351336),\n 'bs_median5': 6.0279176495663505    (4.913064487183709, 7.327876471004487),\n 'bs_median6': 1.0883677296546017    (1.0254060033158392, 1.1818624336827042),\n 'bs_std1': 1.7780097801362074    (1.6017818937482753, 1.9792799437921245),\n 'bs_std2': 0.8811669037969613    (0.8230879332368496, 0.9600774257826834),\n 'bs_std3': 1.0136869214993915    (0.8197738422815288, 1.218799797414249),\n 'bs_std4': 0.466904787403229    (0.4331503334208533, 0.5073949817722586),\n 'bs_std5': 1.0683835555441004    (0.8635116888908527, 1.2990847254680862),\n 'bs_std6': 0.5226066907204562    (0.4921534175468296, 0.563805265168843),\n 'bs_firstQuartile1': 7.222906491595873    (5.474237731687271, 8.763084897943443),\n 'bs_firstQuartile2': 0.9409936333203218    (0.8539110535038241, 1.0533796933114459),\n 'bs_firstQuartile3': 4.333324436444564    (3.805184202201458, 4.958167438937112),\n 'bs_firstQuartile4': 0.8388126951078968    (0.7915099793050908, 0.9069253316299845),\n 'bs_firstQuartile5': 6.226177368983007    (5.104681283135562, 7.517033403828935),\n 'bs_firstQuartile6': 0.758951010665127    (0.7092043712006988, 0.8273996504767639),\n 'bs_thirdQuartile1': 6.627197643208145    (4.3165366764567565, 8.807019221582305),\n 'bs_thirdQuartile2': 2.1175457210064406    (1.9479873761715805, 2.3487605277446337),\n 'bs_thirdQuartile3': 4.475341483919969    (3.7851105253082142, 5.2596653348656),\n 'bs_thirdQuartile4': 1.5522053998026977    (1.4756867609153441, 1.6747750511451363),\n 'bs_thirdQuartile5': 5.839874203550464    (4.778602708629188, 7.069790523682008),\n 'bs_thirdQuartile6': 1.5266284025401036    (1.4464696551366134, 1.6495855776882362)}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats\n",
    "bootstrap_confidence_of_time_domain_features = {\n",
    "    \"bs_min1\" : bs.bootstrap(np.array(table.min1), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_min2\" : bs.bootstrap(np.array(table.min2), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_min3\" : bs.bootstrap(np.array(table.min3), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_min4\" : bs.bootstrap(np.array(table.min4), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_min5\" : bs.bootstrap(np.array(table.min5), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_min6\" : bs.bootstrap(np.array(table.min6), stat_func=bs_stats.std, alpha=0.1),\n",
    "\n",
    "    \"bs_max1\" : bs.bootstrap(np.array(table.max1), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_max2\" : bs.bootstrap(np.array(table.max2), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_max3\" : bs.bootstrap(np.array(table.max3), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_max4\" : bs.bootstrap(np.array(table.max4), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_max5\" : bs.bootstrap(np.array(table.max5), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_max6\" : bs.bootstrap(np.array(table.max6), stat_func=bs_stats.std, alpha=0.1),\n",
    "\n",
    "    \"bs_mean1\" : bs.bootstrap(np.array(table.mean1), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_mean2\" : bs.bootstrap(np.array(table.mean2), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_mean3\" : bs.bootstrap(np.array(table.mean3), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_mean4\" : bs.bootstrap(np.array(table.mean4), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_mean5\" : bs.bootstrap(np.array(table.mean5), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_mean6\" : bs.bootstrap(np.array(table.mean6), stat_func=bs_stats.std, alpha=0.1),\n",
    "\n",
    "    \"bs_median1\" : bs.bootstrap(np.array(table.median1), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_median2\" : bs.bootstrap(np.array(table.median2), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_median3\" : bs.bootstrap(np.array(table.median3), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_median4\" : bs.bootstrap(np.array(table.median4), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_median5\" : bs.bootstrap(np.array(table.median5), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_median6\" : bs.bootstrap(np.array(table.median6), stat_func=bs_stats.std, alpha=0.1),\n",
    "\n",
    "    \"bs_std1\" : bs.bootstrap(np.array(table.std1), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_std2\" : bs.bootstrap(np.array(table.std2), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_std3\" : bs.bootstrap(np.array(table.std3), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_std4\" : bs.bootstrap(np.array(table.std4), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_std5\" : bs.bootstrap(np.array(table.std5), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_std6\" : bs.bootstrap(np.array(table.std6), stat_func=bs_stats.std, alpha=0.1),\n",
    "\n",
    "    \"bs_firstQuartile1\" : bs.bootstrap(np.array(table['1st quart1']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_firstQuartile2\" : bs.bootstrap(np.array(table['1st quart2']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_firstQuartile3\" : bs.bootstrap(np.array(table['1st quart3']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_firstQuartile4\" : bs.bootstrap(np.array(table['1st quart4']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_firstQuartile5\" : bs.bootstrap(np.array(table['1st quart5']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_firstQuartile6\" : bs.bootstrap(np.array(table['1st quart6']), stat_func=bs_stats.std, alpha=0.1),\n",
    "\n",
    "    \"bs_thirdQuartile1\" : bs.bootstrap(np.array(table['3rd quart1']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_thirdQuartile2\" : bs.bootstrap(np.array(table['3rd quart2']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_thirdQuartile3\" : bs.bootstrap(np.array(table['3rd quart3']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_thirdQuartile4\" : bs.bootstrap(np.array(table['3rd quart4']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_thirdQuartile5\" : bs.bootstrap(np.array(table['3rd quart5']), stat_func=bs_stats.std, alpha=0.1),\n",
    "    \"bs_thirdQuartile6\" : bs.bootstrap(np.array(table['3rd quart6']), stat_func=bs_stats.std, alpha=0.1)\n",
    "}\n",
    "bootstrap_confidence_of_time_domain_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1 (c) iv. Use your judgement to select the three most important time-domain features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Answer : According to above data the three Most important features are - Max, Mean, Median"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (2) 3.7.4. I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression,\n",
    "### i.e. Y = 0 + 1X + 2X2 + 3X3 + .\n",
    "### (a) Suppose that the true relationship between X and Y is linear, i.e. Y = 0 + 1X + . Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "### (b) Answer (a) using test rather than training RSS.\n",
    "### (c) Suppose that the true relationship between X and Y is not linear, but we dont know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "### (d) Answer (c) using test rather than training RSS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Answer:\n",
    "#### (a) The extra polynomial terms allow for a closer fit of the training data, so we would expect the training RSS for cubic regression to be lower than for simple linear regression.\n",
    "\n",
    "#### (b) The true relationship is linear, so simple linear regression would generalize better to unseen data, as it is expected to have lower test RSS. The cubic model is likely to over-fit the training data, and so we would expect it to have a higher test RSS.\n",
    "\n",
    "#### (c) Cubic regression will have a better fit to non-linear data and so its training RSS will be lower.\n",
    "\n",
    "#### (d) The test RSS depends on how far from linear the true relationship$f(x)$ is. If $f(x)$ is more linear than cubic, then cubic regression can over fit, so cubic RSS will be higher and liner RSS will be lower. If $f(x)$ is more cubic than linear, then linear regression can under fit, so linear RSS will be higher and cubic RSS will be lower."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}